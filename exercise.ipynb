{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trsfm = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.1307,), std=(0.3081,))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trsfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "batch_size = 128\n",
    "shuffle = True\n",
    "validation_split = 0.1\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(data_dir, train=True, download=True, transform=trsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:50,  5.07s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_x_list = []\n",
    "dataset_y_list = []\n",
    "\n",
    "# broken_files = []\n",
    "\n",
    "for folder in tqdm(Path(\"./datasets\").iterdir()):\n",
    "    alphabet = str(folder)[-1]\n",
    "\n",
    "    for alpha in folder.iterdir():\n",
    "        try:\n",
    "            im = Image.open(str(alpha))\n",
    "        except:\n",
    "            # broken_files.append(alpha)\n",
    "            continue\n",
    "        \n",
    "        im_tensor = transforms.ToTensor()(im)\n",
    "        dataset_x_list.append(im_tensor)\n",
    "        dataset_y_list.append(ord(alphabet) - 65) # A => 0, B => 1, ... , J => 9\n",
    "\n",
    "# num_broken_files = len(broken_files)\n",
    "# print(\"{} files are broken.\".format(num_broken_files))\n",
    "# for broken_file in broken_files:\n",
    "#     print(broken_file)\n",
    "\n",
    "tensor_x = torch.stack(dataset_x_list)\n",
    "tensor_y = torch.Tensor(dataset_y_list)\n",
    "\n",
    "NotMNIST_dataset = TensorDataset(tensor_x, tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.stack(dataset_x_list)\n",
    "tensor_y = torch.tensor(dataset_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotMNIST_dataset = TensorDataset(tensor_x, tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NotMNIST_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotMnistDataset(TensorDataset):\n",
    "\n",
    "    def __init__(self, training = True):\n",
    "        dataset_x_list = []\n",
    "        dataset_y_list = []\n",
    "\n",
    "        for folder in tqdm(Path(\"./datasets\").iterdir()):\n",
    "            alphabet = str(folder)[-1]\n",
    "\n",
    "            for alpha in tqdm(folder.iterdir()):\n",
    "                try:\n",
    "                    im = Image.open(str(alpha))\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                im_tensor = transforms.ToTensor()(im)\n",
    "                dataset_x_list.append(im_tensor)\n",
    "                dataset_y_list.append(ord(alphabet) - 65) # A => 0, B => 1, ... , J => 9\n",
    "\n",
    "        self.tensor_x = torch.stack(dataset_x_list)\n",
    "        self.tensor_y = torch.tensor(dataset_y_list)\n",
    "\n",
    "        self.tensors = (self.tensor_x, self.tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52912it [00:05, 9941.94it/s] \n",
      "52912it [00:05, 10087.12it/s]\n",
      "52912it [00:05, 10252.97it/s]\n",
      "52912it [00:05, 10336.02it/s]\n",
      "52912it [00:05, 10299.65it/s]\n",
      "52912it [00:05, 10441.97it/s]\n",
      "52912it [00:05, 10433.35it/s]\n",
      "52912it [00:05, 10052.57it/s]\n",
      "52911it [00:05, 10313.77it/s]\n",
      "52912it [00:05, 10193.46it/s]\n",
      "10it [00:51,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "nmd = NotMnistDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'Knock Knock',\n",
       " 'channel': 'aa',\n",
       " 'text': 'Your training has started ðŸŽ¬',\n",
       " 'icon_emoji': ':clapper:'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump = {\n",
    "    \"username\": \"Knock Knock\",\n",
    "    \"channel\": 'aa'\n",
    "}\n",
    "\n",
    "contents = []\n",
    "\n",
    "\n",
    "contents.append(\"Your training has started ðŸŽ¬\")\n",
    "\n",
    "\n",
    "dump[\"text\"] = \"\\n\".join(contents)\n",
    "dump[\"icon_emoji\"] = \":clapper:\"\n",
    "\n",
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c1e26d664f99b3801129e248e3451b99480d77c2ba91ecf22573d735535c5fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
